{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llm_from_scratch.c4 import GPTModel, GPTConfig\n",
    "\n",
    "# 1 We shorten the context length from 1,024 to 256 tokens.\n",
    "# 2 It’s possible and common to set dropout to 0.\n",
    "GPT_CONFIG_124M: GPTConfig = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,  # 1\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,  # 2\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from llm_from_scratch.c4 import generate_text_simple\n",
    "from llm_from_scratch.c5 import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [16833, 3626, 6100],  # [\"every effort moves\",\n",
    "        [40, 1107, 588],\n",
    "    ]\n",
    ")  #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor(\n",
    "    [\n",
    "        [3626, 6100, 345],  # [\" effort moves you\",\n",
    "        [1107, 588, 11311],\n",
    "    ]\n",
    ")  #  \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():  # 1\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)  # 2\n",
    "print(probas.shape)\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4537e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6771e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_from_scratch.c2 import VERDICT_PATH\n",
    "\n",
    "text_data = VERDICT_PATH.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_from_scratch.c2 import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def calc_loss_batch(\n",
    "    input_batch: torch.Tensor,\n",
    "    target_batch: torch.Tensor,\n",
    "    model: nn.Module,\n",
    "    device: str | torch.device,\n",
    "):\n",
    "    input_batch = input_batch.to(device, copy=True)  # 1\n",
    "    target_batch = target_batch.to(device, copy=True)\n",
    "    logits = model(input_batch)\n",
    "    loss = F.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(\n",
    "    data_loader: DataLoader,\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    num_batches: int | None = None,\n",
    "):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    if len(data_loader) == 0:\n",
    "        return math.nan\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)  # 1\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))  # 2\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()  # 3\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches  # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device chosen is mps\n",
      "Training loss: 10.987582206726074\n",
      "Validation loss: 10.981103897094727\n",
      "Time: 0.7916\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def pick_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "device = pick_device()\n",
    "print(\"Device chosen is\", device)\n",
    "\n",
    "model.to(device)  # 1\n",
    "with torch.no_grad():  # 2\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)  # 3\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "print(f\"Time: {time.time()-start:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []  # 1\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):  # 2\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # 3\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # 4\n",
    "            optimizer.step()  # 5\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:  # 6\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(  # 7\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # 1\n",
    "    with torch.no_grad():  # 2\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device, copy=True)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # 1\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.723, Val loss 6.598\n",
      "Ep 3 (Step 000025): Train loss 5.204, Val loss 6.351\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.420, Val loss 6.279\n",
      "Ep 4 (Step 000035): Train loss 4.071, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.733, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.852, Val loss 6.180\n",
      "Ep 6 (Step 000050): Train loss 2.429, Val loss 6.140\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.106, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.883, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.321, Val loss 6.239\n",
      "Ep 8 (Step 000070): Train loss 0.986, Val loss 6.243\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.542, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "# MPS has some issue, investigate later.\n",
    "device = torch.device(\"cpu\")  # pick_device()\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),  # 1\n",
    "    lr=0.0004,\n",
    "    weight_decay=0.1,\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.900, Val loss 10.900\n",
      "Ep 1 (Step 000005): Train loss 9.940, Val loss 9.987\n",
      "Every effort moves you were were of were were were were were were were were were were were were were were were were were of were were were were were were were of were were were were of were of were of were were were were were were were of were were of were\n",
      "Ep 2 (Step 000010): Train loss 8.868, Val loss 9.042\n",
      "Ep 2 (Step 000015): Train loss 8.014, Val loss 8.251\n",
      "Every effort moves you it it it it it it it it it of it it it it of it it it it of it it it of it it it it it it it it it of me it it it it it it it it it it it it it it of\n",
      "Ep 3 (Step 000020): Train loss 6.873, Val loss 7.193\n",
      "Ep 3 (Step 000025): Train loss 6.276, Val loss 6.758\n",
      "Every effort moves you of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of\n",
      "Ep 4 (Step 000030): Train loss 6.116, Val loss 6.682\n",
      "Ep 4 (Step 000035): Train loss 6.077, Val loss 6.680\n",
      "Every effort moves you..................................................\n",
      "Ep 5 (Step 000040): Train loss 6.025, Val loss 6.690\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 6 (Step 000045): Train loss 6.050, Val loss 6.689\n",
      "Ep 6 (Step 000050): Train loss 6.055, Val loss 6.682\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 7 (Step 000055): Train loss 6.081, Val loss 6.689\n",
      "Ep 7 (Step 000060): Train loss 6.044, Val loss 6.684\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 8 (Step 000065): Train loss 5.998, Val loss 6.671\n",
      "Ep 8 (Step 000070): Train loss 6.043, Val loss 6.682\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 9 (Step 000075): Train loss 6.012, Val loss 6.712\n",
      "Ep 9 (Step 000080): Train loss 6.034, Val loss 6.772\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 10 (Step 000085): Train loss 5.989, Val loss 6.791\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "# Using MPS (seems to be broken somehow)\n",
    "#  See also https://discuss.pytorch.org/t/training-doesnt-converge-when-running-on-m1-pro-gpu-mps-device/157918/12\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# MPS has some issue, investigate later.\n",
    "mps = torch.device(\"mps\")  # pick_device()\n",
    "model_mps = GPTModel(GPT_CONFIG_124M)\n",
    "model_mps.to(mps)\n",
    "optimizer_mps = torch.optim.AdamW(\n",
    "    model_mps.parameters(),  # 1\n",
    "    lr=0.0004,\n",
    "    weight_decay=0.1,\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses_mps, val_losses_mps, tokens_seen_mps = train_model_simple(\n",
    "    model_mps,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer_mps,\n",
    "    mps,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()  # 1\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 2\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████████████████████████████████████████| 77.0/77.0 [00:00<00:00, 83.5kiB/s]\n",
      "encoder.json: 100%|██████████████████████████████████████████| 1.04M/1.04M [00:00<00:00, 2.66MiB/s]\n",
      "hparams.json: 100%|████████████████████████████████████████████| 90.0/90.0 [00:00<00:00, 67.5kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████████████████████| 498M/498M [02:29<00:00, 3.33MiB/s]\n",
      "model.ckpt.index: 100%|██████████████████████████████████████| 5.21k/5.21k [00:00<00:00, 2.06MiB/s]\n",
      "model.ckpt.meta: 100%|█████████████████████████████████████████| 471k/471k [00:00<00:00, 1.81MiB/s]\n",
      "vocab.bpe: 100%|███████████████████████████████████████████████| 456k/456k [00:00<00:00, 1.75MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# This is downloaded with the the `urlretrieve`, so the import needs to stay here.\n",
    "from gpt_download import download_and_load_gpt2  # noqa: E402\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \" \"Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):  # 1\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):  # 2\n",
    "        q_w, k_w, v_w = np.split(  # 3\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T\n",
    "        )\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T,\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"],\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T,\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T,\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"],\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.weight = assign(\n",
    "            gpt.trf_blocks[b].norm1.weight, params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm1.bias = assign(\n",
    "            gpt.trf_blocks[b].norm1.bias, params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.weight = assign(\n",
    "            gpt.trf_blocks[b].norm2.weight, params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.bias = assign(\n",
    "            gpt.trf_blocks[b].norm2.bias, params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "\n",
    "    gpt.final_norm.weight = assign(gpt.final_norm.weight, params[\"g\"])\n",
    "    gpt.final_norm.bias = assign(gpt.final_norm.bias, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])  # 4”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None\n",
    "):\n",
    "    for _ in range(max_new_tokens):  # 1\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:  # 2\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits\n",
    "            )\n",
    "        if temperature > 0.0:  # 3\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:  # 4\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:  # 5\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Both make sense, though different.\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"mps\")\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
